{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ec8285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from skimage import io\n",
    "import os\n",
    "\n",
    "class SportLoader(data.Dataset):\n",
    "    def __init__(self, mode, transform=None):\n",
    "        self.mode = mode\n",
    "        self.img_name = sorted(os.listdir(f\"./{mode}\"))\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image_path = f\"./{self.mode}/{self.img_name[index]}\"\n",
    "        self.img = io.imread(image_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            self.img = self.transform(self.img)\n",
    "        \n",
    "        return self.img, self.img_name[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd2d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool6 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool11 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv12 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool16 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv19 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool21 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.ftn1 = nn.Flatten()\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = F.relu((self.conv1(input)))\n",
    "        output = F.relu(self.pool3(output))\n",
    "\n",
    "        output = F.relu((self.conv4(output)))\n",
    "        output = F.relu(self.pool6(output))\n",
    "\n",
    "        output = F.relu((self.conv7(output)))\n",
    "        output = F.relu(self.pool11(output))\n",
    "    \n",
    "        output = F.relu((self.conv12(output)))\n",
    "        output = F.relu(self.pool16(output))\n",
    "    \n",
    "        output = F.relu((self.conv19(output)))\n",
    "        output = F.relu(self.pool21(output))\n",
    "        \n",
    "        output = self.ftn1(output)\n",
    "        output = self.fc3(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce6d6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.1, 0.1, 0.1]\n",
    "train_transforms = transforms.Compose([\n",
    "    \n",
    "    transforms.ToPILImage(),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     transforms.RandomRotation(5, expand=False, center=(112, 112)),\n",
    "#     transforms.CenterCrop((210, 210)),\n",
    "    transforms.Resize((128, 128), transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_dataset = SportLoader(\"test\", transform=train_transforms)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd63cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.no_grad at 0x23d7f1e72e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "path = \"./model.pt\"\n",
    "model = Network()\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()\n",
    "torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a47ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import pandas\n",
    "\n",
    "\n",
    "df = pandas.DataFrame(columns=('names', 'label'))\n",
    "cnt = 0\n",
    "for test_x, file in test_loader:\n",
    "    test_x = Variable(test_x.float())\n",
    "    test_pred = model(test_x)\n",
    "    predicted = torch.max(test_pred.data, 1)[1]\n",
    "#     print(file[0], predicted.tolist()[0])\n",
    "    df.loc[cnt] = [file[0]] + predicted.tolist()\n",
    "#     df.append({'names':file[0], 'label':predicted.tolist()[0]}, ignore_index=True)\n",
    "    cnt+=1\n",
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80c084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
